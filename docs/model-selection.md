# Overview

- 本課題に対しては、ベースライン(SARIMA, LightGBM)を作成し、PatchTSTを比較対象とする。
- 最終的には、それらをアンサンブルすることで予測精度の向上を目指す。

# STEP1: ベースラインモデルの構築

- SARIMAモデルの構築
    - トレーニングデータに対してSARIMAモデルを適用し、予測精度を評価する。
    - ハイパーパラメータのチューニングを行い、最適なモデルを選定する。
- LightGBMモデルの構築
    - トレーニングデータに対してLightGBMモデルを適用し、予測精度を評価する。
    - 特徴量エンジニアリングを実施し、モデルの性能向上を図る。
    - ハイパーパラメータのチューニングを行い、最適なモデルを選定する。

# STEP2: PatchTSTモデルの適用

- PatchTSTモデルの導入
    - PatchTSTモデルを実装し、トレーニングデータに対して適用する。
    - モデルのハイパーパラメータを調整し、最適な設定を見つける。
- 予測精度の評価
    - トレーニングデータに対する予測精度を評価し、ベースラインモデルと比較する。

# STEP3: アンサンブルモデルの構築

- ベースラインモデルとPatchTSTモデルのアンサンブル
    - 各モデルの予測結果を組み合わせ、アンサンブルモデルを構築する。
    - アンサンブル手法として、単純平均、加重平均、スタッキングなどを検討する。
- 予測精度の評価
    - アンサンブルモデルの予測精度を評価し、各単一モデルと比較する。

# 除外するモデル

- Prophetモデル
    - 理由: Prophetは主に日次・週次・年次の季節性を持つデータに適しており、今回の時系列データの特性には必ずしも合致しないため。
    - また、他のモデル（SARIMA, LightGBM, PatchTST）で十分な予測精度が得られることが期待されるため。
- VARモデル
    - 理由: VARモデルは多変量時系列データに適しているが、今回の課題では単一のターゲット変数に焦点を当てているため。
    - さらに、VARモデルは計算コストが高く、他のモデルと比較して効率的でない可能性があるため。
- 単純LSTM/GRUモデル
    - 理由: PatchTSTがTransformerベースのモデルであり、LSTM/GRUよりも長期依存関係を捉える能力が高いため。
    - また、LSTM/GRUは学習に時間がかかることが多く、PatchTSTの方が効率的である可能性が高いため。

# 選択の実装
- レジストリシステムとpydanticを使用して、モデルの選択とパラメータ管理を行う。
- 各モデルは独自のクラスとして実装され、共通のインターフェースを持つ。
- `config/exp_001.yml`で使用するモデルとそのパラメータを指定することで、柔軟にモデルを切り替え可能とする。
- `scripts/main.py`で指定されたモデルをインスタンス化し、トレーニングおよび予測を実行する。
- これにより、実験管理が容易になり、異なるモデルの比較が効率的に行える。
